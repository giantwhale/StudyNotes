{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "Jason Brownlee's blog post: https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.6\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-550011ed8f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpyversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}.{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python version: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpyversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tensorflow version: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "pyversion = '{}.{}'.format(sys.version_info.major, sys.version_info.minor)\n",
    "print('python version: ' + pyversion)\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "print(\"tensorflow version: \" + tf.__version__)\n",
    "from keras.datasets import mnist\n",
    "print('keras version: ' + keras.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABrCAYAAABnlHmpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGaEGXUQkI9Sgi4hkxP8DDbCs5eBXDN0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4220e6c0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "for i in range(4):\n",
    "    plt.subplot(141+i)\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model with Multi-Layer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(seed)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flatten 28x28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "# Normalize pixel values to 0. to 1.\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encodes the output\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the training and validation set\n",
    "idx = numpy.hstack([numpy.ones(10000), numpy.zeros(50000)])\n",
    "numpy.random.shuffle(idx)\n",
    "X_train, X_valid = X_train[idx==0, :], X_train[idx==1, :]\n",
    "y_train, y_valid = y_train[idx==0], y_train[idx==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Define the Model. We use a simple neural network with one hidden layer with the same number of neurons as the inputs (784). A Rrectifier activation function is used for the neurons in the hidden layer. \n",
    "\n",
    "![OneLayerNN](https://github.com/giantwhale/StudyNotes/blob/master/DeepLearning/imgs/neural_net_one_layer_fully_connected.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, # output has the same length as the input \n",
    "                    input_dim=num_pixels, \n",
    "                    kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1s - loss: 0.3030 - acc: 0.9146 - val_loss: 0.1583 - val_acc: 0.9552\n",
      "Epoch 2/10\n",
      "1s - loss: 0.1221 - acc: 0.9649 - val_loss: 0.1159 - val_acc: 0.9652\n",
      "Epoch 3/10\n",
      "1s - loss: 0.0797 - acc: 0.9772 - val_loss: 0.0927 - val_acc: 0.9730\n",
      "Epoch 4/10\n",
      "1s - loss: 0.0554 - acc: 0.9839 - val_loss: 0.0848 - val_acc: 0.9745\n",
      "Epoch 5/10\n",
      "1s - loss: 0.0407 - acc: 0.9882 - val_loss: 0.0854 - val_acc: 0.9743\n",
      "Epoch 6/10\n",
      "1s - loss: 0.0302 - acc: 0.9920 - val_loss: 0.0704 - val_acc: 0.9794\n",
      "Epoch 7/10\n",
      "1s - loss: 0.0218 - acc: 0.9948 - val_loss: 0.0666 - val_acc: 0.9797\n",
      "Epoch 8/10\n",
      "1s - loss: 0.0156 - acc: 0.9964 - val_loss: 0.0680 - val_acc: 0.9806\n",
      "Epoch 9/10\n",
      "1s - loss: 0.0115 - acc: 0.9977 - val_loss: 0.0670 - val_acc: 0.9810\n",
      "Epoch 10/10\n",
      "1s - loss: 0.0088 - acc: 0.9985 - val_loss: 0.0666 - val_acc: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4221980b00>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10,\n",
    "         batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 1.92%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: {:.2f}%\".format(100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN\n",
    "\n",
    "References: https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Convolutional Neural Network, we take into consideration the geometric location of each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "# Note: we are using gray scale here, so pixels is set to 1. For RGB colored\n",
    "#       images, we set pixels to 3.\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "# Standarization\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the training and validation set\n",
    "idx = numpy.hstack([numpy.ones(10000), numpy.zeros(50000)])\n",
    "numpy.random.shuffle(idx)\n",
    "X_train, X_valid = X_train[idx==0, :], X_train[idx==1, :]\n",
    "y_train, y_valid = y_train[idx==0], y_train[idx==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our CNN model.\n",
    "\n",
    "1. The first layer is a conv layer with 32 feature maps, which with the size of 5x5 and a RELU activation. (Each **filter** is a 5x5 pad that we use to scan over the image. thus the output tensor has 32 layers as the last dimension).\n",
    "\n",
    "2. Next we define a **Max Pooling** layer.\n",
    "\n",
    "3. The next layer is a regularization layer using **Dropout** with rate 20%.\n",
    "\n",
    "4. Next is a layer that converts the 2D matrix data to a vector through the **Flatten** operation. \n",
    "\n",
    "5. Next a fully connected layer with 128 neurons and RELU activation\n",
    "\n",
    "6. Finally, the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), \n",
    "                     input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "27s - loss: 0.2738 - acc: 0.9204 - val_loss: 0.1152 - val_acc: 0.9677\n",
      "Epoch 2/10\n",
      "8s - loss: 0.0794 - acc: 0.9761 - val_loss: 0.0710 - val_acc: 0.9775\n",
      "Epoch 3/10\n",
      "8s - loss: 0.0549 - acc: 0.9829 - val_loss: 0.0540 - val_acc: 0.9844\n",
      "Epoch 4/10\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid), \n",
    "          epochs=10, batch_size=200, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
